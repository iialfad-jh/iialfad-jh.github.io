<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>IIALFAD</title>
  
  <subtitle>一个 RUNOOB 博客</subtitle>
  <link href="https://iialfad-jh.github.io/atom.xml" rel="self"/>
  
  <link href="https://iialfad-jh.github.io/"/>
  <updated>2026-01-29T08:36:16.770Z</updated>
  <id>https://iialfad-jh.github.io/</id>
  
  <author>
    <name>ZJH</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>顶会论文阅读[3/] | ICCV 2025 | HOPS</title>
    <link href="https://iialfad-jh.github.io/2026/01/29/HOPS/"/>
    <id>https://iialfad-jh.github.io/2026/01/29/HOPS/</id>
    <published>2026-01-29T07:35:55.000Z</published>
    <updated>2026-01-29T08:36:16.770Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;【论文解读】HOPS：一种超维单点符号来表示所有地点&quot;&gt;&lt;a href=&quot;#【论文解读】HOPS：一种超维单点符号来表示所有地点&quot; class=&quot;headerlink&quot; title=&quot;【论文解读】HOPS：一种超维单点符号来表示所有地点&quot;&gt;&lt;/a&gt;【论文解读】HOPS：一种超维单点符号来表示所有地点&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;论文题目：&lt;/strong&gt; A Hyperdimensional One Place Signature to Represent Them All: Stackable Descriptors For Visual Place Recognition&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;核心任务：&lt;/strong&gt; 视觉地点识别（Visual Place Recognition, VPR）在剧烈环境变化下的鲁棒性提升&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;本文介绍的 HOPS (Hyperdimensional One Place Signatures) 方法，通过一种超维计算（Hyperdimensional Computing, HDC）框架，旨在解决传统多参考系VPR方法中计算成本与存储需求随参考地图数量线性增长的问题，同时显著提升地点识别的召回率。&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;/images/hops/inreoduction.png&quot; alt=&quot;using hyperdimensional computing to fuse descriptors from multiple reference sets with no dimensionality increase.&quot; style=&quot;width: 80%; display: block; margin: 0 auto;&quot; /&gt;</summary>
    
    
    
    
    <category term="VPR" scheme="https://iialfad-jh.github.io/tags/VPR/"/>
    
    <category term="Hyperdimensional One Place Signatures(HDC)" scheme="https://iialfad-jh.github.io/tags/Hyperdimensional-One-Place-Signatures-HDC/"/>
    
    <category term="Gaussian Random Projection(GRP)" scheme="https://iialfad-jh.github.io/tags/Gaussian-Random-Projection-GRP/"/>
    
    <category term="ICCV 2025" scheme="https://iialfad-jh.github.io/tags/ICCV-2025/"/>
    
  </entry>
  
  <entry>
    <title>顶会论文阅读[2/] | ICCV 2025 | VPR-Cloak</title>
    <link href="https://iialfad-jh.github.io/2026/01/22/VPR-CLOAK/"/>
    <id>https://iialfad-jh.github.io/2026/01/22/VPR-CLOAK/</id>
    <published>2026-01-22T13:45:50.000Z</published>
    <updated>2026-01-29T07:47:00.711Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;【论文解读】VPR-Cloak-针对视觉地点识别隐私保护的首次探索&quot;&gt;&lt;a href=&quot;#【论文解读】VPR-Cloak-针对视觉地点识别隐私保护的首次探索&quot; class=&quot;headerlink&quot; title=&quot;【论文解读】VPR-Cloak: 针对视觉地点识别隐私保护的首次探索&quot;&gt;&lt;/a&gt;【论文解读】VPR-Cloak: 针对视觉地点识别隐私保护的首次探索&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;论文题目&lt;/strong&gt;：VPR-Cloak: A First Look at Privacy Cloak Against Visual Place Recognition&lt;br&gt;&lt;strong&gt;核心任务&lt;/strong&gt;：针对视觉地点识别（VPR）系统的图像隐私保护，防止未经授权的位置信息泄露。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文介绍的 &lt;strong&gt;VPR-Cloak&lt;/strong&gt; 方法，通过一种&lt;strong&gt;显著性感知先验引导的扰动优化（Saliency-Aware Prior Guided Perturbation Optimization, SAP-PO）&lt;/strong&gt; 框架，旨在解决视觉地点识别场景下，现有隐私保护方法在黑盒攻击鲁棒性、视觉不可察觉性以及实时处理性能方面难以兼顾的问题。&lt;/p&gt;
&lt;img src=&quot;/images/vpr-cloak/introduction.png&quot; alt=&quot;introduction&quot; style=&quot;width: 50%; display: block; margin: 0 auto;&quot; /&gt;</summary>
    
    
    
    
    <category term="VPR" scheme="https://iialfad-jh.github.io/tags/VPR/"/>
    
    <category term="ICCV 2025" scheme="https://iialfad-jh.github.io/tags/ICCV-2025/"/>
    
    <category term="Private" scheme="https://iialfad-jh.github.io/tags/Private/"/>
    
    <category term="论文笔记" scheme="https://iialfad-jh.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>顶会论文阅读[1/] | ICCV 2025 | GenPriv</title>
    <link href="https://iialfad-jh.github.io/2026/01/22/Less-Static-More-Private/"/>
    <id>https://iialfad-jh.github.io/2026/01/22/Less-Static-More-Private/</id>
    <published>2026-01-22T05:07:41.000Z</published>
    <updated>2026-01-23T13:30:55.627Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;【论文解读】GenPriv：基于生成式解耦学习的可迁移隐私保护动作识别&quot;&gt;&lt;a href=&quot;#【论文解读】GenPriv：基于生成式解耦学习的可迁移隐私保护动作识别&quot; class=&quot;headerlink&quot; title=&quot;【论文解读】GenPriv：基于生成式解耦学习的可迁移隐私保护动作识别&quot;&gt;&lt;/a&gt;【论文解读】GenPriv：基于生成式解耦学习的可迁移隐私保护动作识别&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;论文题目&lt;/strong&gt;：Less Static, More Private: Towards Transferable Privacy-Preserving Action Recognition by Generative Decoupled Learning&lt;br&gt;&lt;strong&gt;核心任务&lt;/strong&gt;：隐私保护动作识别 (Privacy-Preserving Action Recognition, PPAR)、域适应 (Domain Adaptation)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文介绍的 &lt;strong&gt;GenPriv&lt;/strong&gt; 方法，通过一种新颖的 &lt;strong&gt;生成式解耦学习（Generative Decoupled Learning）&lt;/strong&gt; 框架，旨在解决跨域场景下的隐私保护与动作识别的权衡问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/less-static-more-private/1.png&quot; alt=&quot;Comparison between the existing PPAR methods and ourGenPriv.&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="ICCV 2025" scheme="https://iialfad-jh.github.io/tags/ICCV-2025/"/>
    
    <category term="Private" scheme="https://iialfad-jh.github.io/tags/Private/"/>
    
    <category term="PPAR" scheme="https://iialfad-jh.github.io/tags/PPAR/"/>
    
    <category term="Domain Adaptation" scheme="https://iialfad-jh.github.io/tags/Domain-Adaptation/"/>
    
    <category term="论文笔记" scheme="https://iialfad-jh.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>主定理回顾</title>
    <link href="https://iialfad-jh.github.io/2026/01/05/%E4%B8%BB%E5%AE%9A%E7%90%86%E5%9B%9E%E9%A1%BE/"/>
    <id>https://iialfad-jh.github.io/2026/01/05/%E4%B8%BB%E5%AE%9A%E7%90%86%E5%9B%9E%E9%A1%BE/</id>
    <published>2026-01-05T06:34:45.000Z</published>
    <updated>2026-01-05T06:37:54.133Z</updated>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;主定理（Master Theorem）&lt;/strong&gt; 是算法分析中用于解决&lt;strong&gt;分治法（Divide and Conquer）&lt;/strong&gt; 递归关系式的一个“万能公式”。它能让你直接通过公式推导出时间复杂度，而不需要画递归树或进行复杂的数学归纳。&lt;/p&gt;
&lt;p&gt;以下是它计算复杂度的详细步骤和逻辑：&lt;/p&gt;</summary>
    
    
    
    
    <category term="Algorithm" scheme="https://iialfad-jh.github.io/tags/Algorithm/"/>
    
  </entry>
  
</feed>
